# ğŸ’»ğŸ“– hacker-laws-tr

ProgramcÄ±larÄ±n faydalÄ± bulacaÄŸÄ± yasalar, teoriler, prensipler ve desenler.

ğŸ‡¬ğŸ‡§ [English / Ä°ngilizce Ä°Ã§in](https://github.com/dwmkerr/hacker-laws) - TeÅŸekkÃ¼rler [Dave Kerr](https://github.com/dwmkerr)!

ğŸ‡¨ğŸ‡³ [ä¸­æ–‡ / Ã‡ince Ä°Ã§in](https://github.com/nusr/hacker-laws-zh) - TeÅŸekkÃ¼rler [Steve Xu](https://github.com/nusr)!

<!-- vim-markdown-toc GFM -->

* [GiriÅŸ](#giriÅŸ)
* [Yasalar](#kanunlar)
    * [Amdahl YasasÄ±](#amdahl-yasasÄ±)
    * [Brooks YasasÄ±](#brooks-yasasÄ±)
    * [Conway YasasÄ±](#conway-yasasÄ±)
    * [Hanlon'un UsturasÄ±](#hanlonun-usturasÄ±)
    * [Hofstadter YasasÄ±](#hofstadter-yasasÄ±)
    * [Hype DÃ¶ngÃ¼sÃ¼ ve Amara YasasÄ±](#hype-dÃ¶ngÃ¼sÃ¼-ve-amara-yasasÄ±)
    * [Hyrum YasasÄ± (Arabirimlerin Ã–rtÃ¼lÃ¼ Hukuku)](#hyrum-yasasÄ±-arabirimlerin-Ã¶rtÃ¼lÃ¼-hukuku)
    * [Moore YasasÄ±](#moore-yasasÄ±)
    * [Parkinson YasasÄ±](#parkinson-yasasÄ±)
    * [Putt YasasÄ±](#putt-yasasÄ±)
    * [KarmaÅŸÄ±klÄ±ÄŸÄ±n KorunmasÄ± YasasÄ± (Tesler YasasÄ±)](#karmaÅŸÄ±klÄ±ÄŸÄ±n-korunmasÄ±-yasasÄ±-tesler-yasasÄ±)
    * [SÄ±zdÄ±ran Soyutlamalar YasasÄ±](#sÄ±zdÄ±ran-soyutlamalar-yasasÄ±)
    * [Ã–nemsizlik YasasÄ±](#Ã¶nemsizlik-yasasÄ±)
    * [Unix Felsefesi](#unix-felsefesi)
    * [The Spotify Model](#the-spotify-model)
    * [Wadler's Law](#wadlers-law)
* [Principles](#principles)
    * [The Pareto Principle (The 80/20 Rule)](#the-pareto-principle-the-8020-rule)
    * [The Robustness Principle (Postel's Law)](#the-robustness-principle-postels-law)
    * [SOLID](#solid)
    * [The Single Responsibility Principle](#the-single-responsibility-principle)
    * [The Open/Closed Principle](#the-openclosed-principle)
    * [The Liskov Substitution Principle](#the-liskov-substitution-principle)
    * [The Interface Segregation Principle](#the-interface-segregation-principle)
    * [The Dependency Inversion Principle](#the-dependency-inversion-principle)
    * [The DRY Principle](#the-dry-principle)
* [Reading List](#reading-list)
* [TODO](#todo)

<!-- vim-markdown-toc -->

## GiriÅŸ

Ä°nsanlarÄ±n geliÅŸtirme hakkÄ±nda konuÅŸurken tartÄ±ÅŸtÄ±klarÄ± birÃ§ok yasa var. Bu depo, en yaygÄ±n olanlardan bazÄ±larÄ±nÄ±n referanslarÄ±nÄ± ve Ã¶zetini barÄ±ndÄ±rÄ±r. KatkÄ±da bulunmak iÃ§in PR aÃ§Ä±p gÃ¶nderebilirsiniz!

â—: Bu depo yasalarÄ±n, prensiplerin ve modellerin bilgi vermek amaÃ§lÄ± aÃ§Ä±klamalarÄ±nÄ± iÃ§erir ve hiÃ§birini savunma amacÄ± gÃ¼tmez. BunlarÄ±n hangisinin uygulanÄ±p uygulanmayacaÄŸÄ± tamamen tartÄ±ÅŸma konusudur ve yapÄ±lan iÅŸe baÄŸlÄ±dÄ±r.

## Yasalar

Tek tek baÅŸlayalÄ±m!

### Amdahl YasasÄ±

[Wikipedia'da Amdahl YasasÄ±](https://en.wikipedia.org/wiki/Amdahl%27s_law)

> Amdahl YasasÄ± kaynaklarÄ± artÄ±rarak bir hesaplama iÅŸleminin _olasÄ± hÄ±zlanma miktarÄ±nÄ±_ hesaplayan bir formÃ¼lÃ¼ tanÄ±mlar. Genellikle paralel iÅŸleme hesaplarÄ±nda kullanÄ±lÄ±r ve iÅŸlemci sayÄ±sÄ±nÄ±n artÄ±rÄ±lmasÄ±nÄ±n programÄ±n paralelleÅŸtirilebilme kapasitesine baÄŸlÄ± olarak etkisinin doÄŸru ÅŸekilde saplanmasÄ±nÄ± saÄŸlar.

En gÃ¼zel ÅŸu Ã¶rnekle anlatÄ±labilir. Bir programÄ±n iki bÃ¶lÃ¼mden oluÅŸtuÄŸunu dÃ¼ÅŸÃ¼nelim. BÃ¶lÃ¼m A sadece tek iÅŸlemci ile Ã§alÄ±ÅŸtÄ±rÄ±labilir. BÃ¶lÃ¼m B ise paralleÅŸtirilebilecek ÅŸekilde yazÄ±lmÄ±ÅŸ. Bu durumda bu programÄ± Ã§ok iÅŸlemci ile Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda BÃ¶lÃ¼m B'de oluÅŸacak kadar bir kazanÄ±m saÄŸlayabiliriz. BÃ¶lÃ¼m A'da her hangi bir katkÄ± olamaycaktÄ±r.

AÅŸaÄŸÄ±daki diyagram bazÄ± olasÄ± hÄ±z geliÅŸtirmelerine Ã¶rnekler iÃ§eriyor:

![Diyagram: Amdahl's Law](./images/amdahls_law.png)

*(DiyagramÄ±n kaynaÄŸÄ±: By Daniels220 at English Wikipedia, Creative Commons Attribution-Share Alike 3.0 Unported, https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg)*

Diyagramdaki Ã¶rneklerden gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere, eÄŸer bir programÄ±n sadece %50'si paraleleÅŸtirilebiliyorsa 10 iÅŸlemciden sonra iÅŸlemci eklemek hÄ±zda gÃ¶zle gÃ¶rÃ¼nÃ¼r bir artÄ±ÅŸ saÄŸlamÄ±yor ama %95 paralelleÅŸtirilebilen bir programda 1000 iÅŸlemciden sonra bile iÅŸlemci eklemenin hÄ±zÄ± artÄ±rdÄ±ÄŸÄ± gÃ¶zlenebilir.

[Moore YasasÄ±nda](#moore-yasasi) sÃ¶ylenen artÄ±ÅŸÄ±n azalma eÄŸiliminde olmasÄ± ve aynÄ± zamanda iÅŸlemci hÄ±zÄ±nÄ±n artÄ±ÅŸÄ±nda da ivme kaybÄ± olmasÄ±, paralelleÅŸtirilebilme Ã¶zelliÄŸini performans artÄ±ÅŸÄ±nda anahtar duruma getirdi. Grafik programlama bu konuda en belirgin Ã¶rnek. Shader tabanlÄ± modern iÅŸleme ile pixel ve fragmanlarÄ±n paralel olarak render edilebilmesi sayesinde modern grafik kartlarÄ±nda binlerce iÅŸlemci Ã§ekirdeÄŸi olabiliyor.

Ek kaynaklar:

- [Brooks YasasÄ±](#brooks-yasasi)
- [Moore YasasÄ±](#moores-yasasi)

### Brooks YasasÄ±

[Wikipedia'da Brooks YasasÄ±](https://en.m.wikipedia.org/wiki/Brooks%27s_law)

> Gecikmesi kesinleÅŸmiÅŸ projeye yeni insan kaynaÄŸÄ± eklemek projeyi daha da geciktirir.

Bu yasa, gecikmiÅŸ bir projeyi hÄ±zlandÄ±rmak iÃ§in ek insan kaynaÄŸÄ± koymanÄ±n projeyi daha geciktireceÄŸini iddia ediyor. Brook'a gÃ¶re bunun gereksiz bir sadeleÅŸtirme olduÄŸu kesin. Yeni katÄ±lanlarÄ±n adapte edilmesi ve iletiÅŸim karmaÅŸasÄ± hemen etkisini gÃ¶stererek hÄ±zÄ±n yavaÅŸlamasÄ±na sebep olur. AyrÄ±ca, yapÄ±lacak iÅŸlerin birÃ§oÄŸu genellikle daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼nemez ve birden fazla kaynak bu iÅŸlerin yapÄ±lmasÄ± iÃ§in kullanÄ±lmaz. Bu durum beklenen artÄ±ÅŸÄ±n saÄŸlanmamasÄ± ile sonuÃ§lanÄ±r.

MeÅŸhur "Dokuz kadÄ±n ile 1 ayda doÄŸum saÄŸlanamaz" deyimi bu yasanÄ±n en pratik anlatÄ±mÄ±dÄ±r. BazÄ± iÅŸlerin bÃ¶lÃ¼nemediÄŸi veya paralelleÅŸtirilemediÄŸi gerÃ§eÄŸini unutmamak lazÄ±m.

'[The Mythical Man Month](#reading-list)' adlÄ± kitabÄ±n ana konularÄ±ndan biri budur.

Ek kaynaklar:

- [Death March](#todo)
- [Reading List: The Mythical Man Month](#reading-list)

### Conway YasasÄ±

[Wikipedia'da Conway Kanunu](https://en.wikipedia.org/wiki/Conway%27s_law)

Conway yasasi der ki; Ã¼retilen sistemler kendilerini Ã¼reten organizasyonun teknik sÄ±nÄ±rlarÄ±nÄ± yansÄ±tÄ±r. Bu yasa daha Ã§ok organizasonel deÄŸiÅŸiklikler sÄ±rasÄ±nda dikkate alÄ±nÄ±r. EÄŸer bir organizasyon birbirinden baÄŸÄ±msÄ±z kÃ¼Ã§Ã¼k birimlerden oluÅŸuyorsa Ã¼retilen yazÄ±lÄ±mlar da buna uygun olacaktÄ±r.  EÄŸer bu organizasyon servis odaklÄ± dikey yapÄ±landÄ±rÄ±lmÄ±ÅŸsa, yazÄ±lÄ±mlar bunu yansÄ±tacaktÄ±r.

Ek kaynaklar:

- [Spotify Modeli](#spotify-modeli)

### Hanlon'un UsturasÄ±

[Wikipedia'da Hanlon'un UsturasÄ±](https://en.wikipedia.org/wiki/Hanlon%27s_razor)

> AptallÄ±kla layÄ±kÄ±yla aÃ§Ä±klanabilecek bir ÅŸeyi, asla kÃ¶tÃ¼ niyete baÄŸlamayÄ±n.
>
> Robert J. Hanlon

Bu prensip, olumsuz sonuÃ§lara yol aÃ§an eylemlerin, Ã§oÄŸunlukla kÃ¶tÃ¼ niyetin sonucu olmadÄ±ÄŸÄ±nÄ± savunmaktadÄ±r. Aksine, olumsuz sonuÃ§ daha bÃ¼yÃ¼k olasÄ±lÄ±kla bu eylemlerin ve/veya etkinin tam olarak anlaÅŸÄ±lamamasÄ±na baÄŸlÄ±dÄ±r..

### Hofstadter YasasÄ±

[Wikipedia'da Hofstadter YasasÄ±](https://en.wikipedia.org/wiki/Hofstadter%27s_law)

> Bir iÅŸ her zaman umduÄŸundan daha uzun sÃ¼rer, Hofstadter yasasÄ±nÄ± gÃ¶zÃ¶nÃ¼nde bulundursan bile. 
>
> Douglas Hofstadter

Bu yasayÄ± bir iÅŸin ne kadar sÃ¼receÄŸini tahminlenirken hatÄ±rlatÄ±ldÄ±ÄŸÄ± iÃ§in duymuÅŸ olabilirsiniz. Herkesin kabul bir gerÃ§ek var ki, yazÄ±lÄ±m geliÅŸtirmede en kÃ¶tÃ¼ olduÄŸumuz alan iÅŸin ne kadar sÃ¼rede biteceÄŸini tahmin etmektir.

'[GÃ¶del, Escher, Bach: An Eternal Golden Braid](#reading-list)' adlÄ± kitaptan alÄ±ntÄ±.

Ek kaynaklar:

- [Reading List: GÃ¶del, Escher, Bach: An Eternal Golden Braid](#reading-list)

### Hype DÃ¶ngÃ¼sÃ¼ ve Amara YasasÄ±

[Wikipedia'da Hype DÃ¶ngÃ¼sÃ¼](https://en.wikipedia.org/wiki/Hype_cycle)

> Bir teknolojinin kÄ±sa vadede oluÅŸacak etkisini abartÄ±p, uzun vadede oluÅŸacak etkisini hafife alÄ±yoruz.
>
> (Roy Amara)

Hype DÃ¶ngÃ¼sÃ¼ bir teknolojinin zamanla yarattÄ±ÄŸÄ± heyecan ve geliÅŸiminin gÃ¶rsel olarak sunumudur ve Gartner tarafÄ±ndan ilk olarak oluÅŸturulmuÅŸtur. En gÃ¼zel anlatÄ±m aÅŸaÄŸÄ±daki bir gÃ¶rsel ile yapÄ±labilir:

![Hype DÃ¶ngÃ¼sÃ¼](./images/gartner_hype_cycle.png)

*(Resmin KaynaÄŸÄ±: Jeremykemp tarafÄ±ndan Ä°ngilizce Wikipeda'da, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=10547051)*

KÄ±saca anlatmak gerekirse, bu dÃ¶ngÃ¼ her yeni teknolojinin ilk zamanlarÄ±nda teknolojinin kendisi ve olasÄ± etkisi Ã¼zerinde bir heyecan dalgasÄ± oluÅŸtuÄŸunu iddia ediyor. Ekipler yeni teknolojiler hemen kullanmaya Ã§alÄ±ÅŸÄ±yorlar ve genelde kendilerini sonuÃ§tan memnun olmamÄ±ÅŸ bir halde buluyorlar. Bu ya teknolojinin henÃ¼z olgunlaÅŸmamÄ±ÅŸ olmasÄ±ndan, ya da uygulamanÄ±n tam anlamÄ±yla gerÃ§ekleÅŸmemiÅŸ olmasÄ±ndan olabilir. Belirli bir sÃ¼re geÃ§tikten sonra, teknolojinin yeterliliÄŸi ve pratik kullanÄ±m alanlarÄ± artar ve ekipler daha Ã¼retken olmaya baÅŸlar. Roy Amara'nÄ±n sÃ¶zÃ¼ bu durumu en Ã¶zlÃ¼ ÅŸekilde toparlÄ±yor diyebiliriz - "Bir teknolojinin kÄ±sa vadede oluÅŸacak etkisini abartÄ±p, uzun vadede oluÅŸacak etkisini hafife alÄ±yoruz".

### Hyrum YasasÄ± (Arabirimlerin Ã–rtÃ¼lÃ¼ Hukuku)

[Hyrum YasasÄ± Web Sitesi](http://www.hyrumslaw.com/)

> Belli sayÄ±da kullanÄ±cÄ±ya ulaÅŸtÄ±ÄŸÄ±nda,
> servis sÃ¶zleÅŸmesinde ne demiÅŸ olduÄŸunuzdan baÄŸÄ±msÄ±z olarak
> Ã¼rÃ¼nÃ¼nÃ¼zÃ¼n ya da sisteminizin bÃ¼tÃ¼n gÃ¶zlemlenebilir davranÄ±ÅŸlarÄ±
> artÄ±k Ã¼Ã§Ã¼ncÃ¼ kiÅŸilere gÃ¶re ÅŸekillenecektir.
>
> (Hyrum Wright)

Hyrum YasasÄ± gÃ¶re, eÄŸer bir API'nin _oldukÃ§a bÃ¼yÃ¼k sayÄ±labilecek sayÄ±da kullnÄ±cÄ±sÄ±_ olduÄŸunda, artÄ±k bÃ¼tÃ¼n sonuÃ§lar ve davranÄ±ÅŸlar (API sÃ¶zleÅŸmesinde belirtilmemiÅŸ olsalar bile) kullanÄ±cÄ±lara gÃ¶re ÅŸekillenecektir. Buna bir Ã¶rnek olarak bir API'nin tepki sÃ¼resi olabilir. Daha kapsamlÄ± bir Ã¶rnek olarak kullanÄ±cÄ±larÄ±n bir regex ile dÃ¶nen cevap metninin iÃ§inden hatanÄ±n tipini ayÄ±kladÄ±klarÄ± bir senaryoyu dÃ¼ÅŸÃ¼nelim. API sÃ¶zleÅŸmesinde bu cevap metinleri ile ilgili birÅŸey belirtilmemiÅŸ olmasÄ±na ve kullanÄ±cÄ±larÄ±n hata kodunu kullanmalarÄ±nÄ± belirtilmesine raÄŸmen, cevap metnini deÄŸiÅŸtirmeniz _bazÄ±_ kullanÄ±cÄ±larÄ±n metni kullanmalarÄ±ndan dolayÄ± hata ile karÅŸÄ±laÅŸmalarÄ±na sebep olacaktÄ±r.

Ek kaynaklar:

- [The Law of Leaky Abstractions](#the-law-of-leaky-abstractions)
- [XKCD 1172](https://xkcd.com/1172/)

### Moore YasasÄ±

[Wikipedia'da Moore YasasÄ±](https://en.wikipedia.org/wiki/Moore%27s_law)

> Entegre devre iÃ§erisindeki transistÃ¶rlerin sayÄ±sÄ± yaklaÅŸÄ±k olarak iki yÄ±lda bir ikiye katlanÄ±r.

Ã‡oÄŸu zaman yarÄ±-iletken ve Ã§ip teknolojisinin geliÅŸim hÄ±zÄ±nÄ± tahmin etmek iÃ§in kullanÄ±lan Moore yasasÄ±nÄ±n, 1970'lerden 2000'lerin sonlarÄ±na doÄŸru oldukÃ§a doÄŸru olduÄŸu biliyoruz. Son yÄ±llarda, [komponentlerin kÃ¼Ã§Ã¼lmesinde fiziksel sÄ±nÄ±rlara ulaÅŸÄ±ldÄ±ÄŸÄ± iÃ§in](https://en.wikipedia.org/wiki/Quantum_tunnelling) bu tahminlemenin tutmadÄ±ÄŸÄ±nÄ± da sÃ¶yleyebiliriz. Ama paralleÅŸtirmede uzmanlaÅŸÄ±lmasÄ± ve yarÄ±-iletken teknolojilerindeki devrim potensiyelindeki deÄŸiÅŸiklikler Moore YasasÄ±'nÄ±n yakÄ±n zamanda tekrar doÄŸrulanacaÄŸÄ±nÄ± tahminler yapabileceÄŸini dÃ¼ÅŸÃ¼nebiliriz.

### Parkinson YasasÄ±

[Wikipedia'da Parkinson YasasÄ±](https://en.wikipedia.org/wiki/Parkinson%27s_law)

> Bir iÅŸ, daima, bitirilmesi iÃ§in kendisine ayrÄ±lan sÃ¼renin hepsini kapsayacak ÅŸekilde uzar.

Orijinal baÄŸlamÄ±nda, bu kanun bÃ¼rokrasi alanÄ±ndaki Ã§alÄ±ÅŸmalara dayanÄ±yordu. KÃ¶tÃ¼mser bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla yazÄ±lÄ±m geliÅŸtirme giriÅŸimleri iÃ§in de sÃ¶ylenebilir. ÅÃ¶yle ki ekipler genelde proje bitiÅŸ tarihi yaklaÅŸana kadar dÃ¼ÅŸÃ¼k verimde Ã§alÄ±ÅŸÄ±rlar, itiÅŸ tarihi yaklaÅŸtÄ±kÃ§a bitirmek iÃ§in yoÄŸun bir Ã§aba iÃ§ine girerler ve sonuÃ§ olarak aslÄ±nda bitiÅŸ tarihini tutturmuÅŸ olurlar.

Bu yasa ile [Hofstadter YasasÄ±](#hofstadter-yasasÄ±) birleÅŸtirilirse, daha kÃ¶tÃ¼mser bir yasaya ulaÅŸÄ±lÄ±r. Bir iÅŸ bitirilmesi iÃ§in harcanmasÄ± gereken zamanÄ± kapsar ve *her zaman gecikir*.

Ek kaynaklar:

- [Hofstadter YasasÄ±](#hofstadter-yasasÄ±)

### Putt YasasÄ±

[Wikipedia'da Putt YasasÄ±](https://en.wikipedia.org/wiki/Putt%27s_Law_and_the_Successful_Technocrat)

> Teknolojide iki tÃ¼r insan egemendir, yÃ¶netmedikleri ÅŸeyleri anlayanlar ve anlamadÄ±klarÄ± ÅŸeyleri yÃ¶netenler.

Putt yasasÄ±nÄ± Ã§oÄŸunlukla Putt sonucu takip eder:

> Her teknik hiyerarÅŸi, zaman iÃ§inde bir yetkinlik dÃ¶nÃ¼ÅŸÃ¼mÃ¼ geliÅŸtirir.

Bu iki cÃ¼mle, ekiplerin oluÅŸturulmasÄ±nda rol alan farklÄ± seÃ§im kriterleri ve eÄŸilimlerden dolayÄ±, bir organizasyonda Ã§alÄ±ÅŸma katmanlarÄ±nda Ã§ok sayÄ±da yetenekli insan olduÄŸu gibi yÃ¶netim katmanlarÄ±nda da yapÄ±lan iÅŸin karmaÅŸÄ±klÄ±ÄŸÄ±ndan ve zorluklarÄ±ndan haberdar olmayan yÃ¶neticiler olacaktÄ±r. Bunun sebebi [Peter Prensibi](#TODO) or [Dilbert YasasÄ±](#TODO) gibi olgular olabilir.

Bununla birlikte, bunun gibi yasalarÄ±n Ã§ok bÃ¼yÃ¼k genellemeler olduÄŸu ve bazÄ± organizasyon tÃ¼rleri iÃ§in geÃ§erli olabileceÄŸi gibi baÅŸkalarÄ± iÃ§in geÃ§erli olmayacaÄŸÄ± unutulmamalÄ±dÄ±r.

Ek kaynaklar:

- [Peter Prensibi](#TODO)
- [Dilbert YasasÄ±](#TODO)


### KarmaÅŸÄ±klÄ±ÄŸÄ±n KorunmasÄ± YasasÄ± (Tesler YasasÄ±)

[Wikipedia'da KarmaÅŸÄ±klÄ±ÄŸÄ±n KorunmasÄ± YasasÄ±](https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity)

Bu yasa der ki, her sistemde kesinlikle ayÄ±klanamayacak bir miktarda karmaÅŸÄ±klÄ±k vardÄ±r.

Bir sistem ve yazÄ±lÄ±mdaki karmaÅŸÄ±klÄ±klarÄ±n bazÄ±larÄ± dikatsizlik veya yanlÄ±ÅŸlÄ±ktan ortaya Ã§Ä±kar. Bu kÃ¶tÃ¼ kurgulanmÄ±ÅŸ yapÄ±nÄ±n, herhangi bir dikatsizliÄŸin, ya da problemin kÃ¶tÃ¼ modellenmesinin sonucu olabilir. Bu tarz karmaÅŸÄ±klÄ±klar giderilebilir ve sistemden ayÄ±klanabilir. Bunun yanÄ±nda, bazÄ± karmaÅŸÄ±klÄ±klar sistemin gerÃ§ekleridir yani sistemin Ã§Ã¶zmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± problemin doÄŸasÄ± gereÄŸi ortaya Ã§Ä±karlar. Bu tarz karmaÅŸÄ±klÄ±klar sistem iÃ§inde farklÄ± yerlere taÅŸÄ±nabilirler ama sistemden ayÄ±klanamazlar.

O yasanÄ±n farklÄ± bir yansÄ±masÄ± olarak ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼lebilir, eÄŸer bir karmaÅŸÄ±klÄ±k esastan geliyorsa ve sistem sadeleÅŸtirilerek bile ayÄ±klanamÄ±yorsa, daha karmaÅŸÄ±k birÅŸekilde davranmasÄ± beklenen kullanÄ±cÄ±nÄ±n tarafÄ±na taÅŸÄ±nabilir.

### SÄ±zdÄ±ran Soyutlamalar YasasÄ±

[SÄ±zdÄ±ran Soyutlamalar YasasÄ±, Joel on Software](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)

> Ã–nemsiz sayÄ±lmayacak bÃ¼tÃ¼n soyutlamar belli Ã¶lÃ§Ã¼de sÄ±zÄ±ntÄ± iÃ§erir.
>
> (Joel Spolsky)

Bu yasa, karmaÅŸÄ±k sistemleri sadeleÅŸtirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z soyutlamalarÄ±n bazÄ± durumlarda soyutlamanÄ±n altÄ±ndaki sistemin Ã¶ÄŸelerini sorunlarÄ± ile birlikte sÄ±zdÄ±rÄ±r ve bu da beklenmedik davranÄ±ÅŸlar ortaya Ã§Ä±kmasÄ± ile sonuÃ§lanÄ±r.

Dosya aÃ§ma ve okuma iÅŸlemlerini Ã¶rneklemek iÃ§in kullanabiliriz. Dosya sistemi arayÃ¼zleri altta yeralan Ã§ekirdek sistemlerinin bir soyutlamasÄ±dÄ±r, ki Ã§ekirdek sistemleri de aslÄ±nda manyetik plakalardaki (fash disk ya da SDD) veriyi  fiziksel olarak deÄŸiÅŸtiren iÅŸlemlerin soyutlamasÄ±dÄ±r. Ã‡oÄŸu durumda, bir dosyayÄ± ikili sistemdeki verilerin akÄ±ÅŸÄ± olarak soyutlamak iÅŸe yarar. Manyetik sÃ¼rÃ¼cÃ¼ler sÄ±ralÄ± okuma yapÄ±ldÄ±ÄŸÄ±nda rastgele eriÅŸimli sÃ¼rÃ¼cÃ¼lere gÃ¶re daha hÄ±zlÄ±dÄ±r (sayfalama hatalarÄ±nÄ±n artmasÄ±ndan dolayÄ±) ama bu durum SDD sÃ¼rÃ¼cÃ¼lerle karÅŸÄ±laÅŸtÄ±rmada geÃ§erli deÄŸildir. Bu durumun Ã¼stesinden gelmek iÃ§in, detaylarÄ±n altÄ±nda yatan bilgileri (yani geliÅŸtiricinin bilmesi gereken uygulama detaylarÄ±nÄ±) soyutlamanÄ±n sÄ±zdÄ±rÄ±yor olacaÄŸÄ± dikkate alÄ±nmalÄ±dÄ±r.

YukarÄ±da verdiÄŸimiz Ã¶rnek daha fazla soyutlanma gÃ¶z Ã¶nÄŸnde bulundurulursa daha da karmaÅŸÄ±klabilir. Linux iÅŸletim sistemi dosyalara bir aÄŸ Ã¼zerinden eriÅŸilmesine olanak saÄŸlÄ±yor ama bu dosyalar sanki yerel dosyalarmÄ±ÅŸ gibi gÃ¶sterilir. Bu soyutlama da eÄŸer bir network sorunu olursa sÄ±zÄ±ntÄ± oluÅŸturur. EÄŸer bir uygulama geliÅŸtirici bu tÃ¼r dosyalarÄ± normal dosyalarmÄ±ÅŸ gibi dÃ¼ÅŸÃ¼nerek geliÅŸtirme yaparsa, aÄŸzda oluÅŸan herhangi bir gecikme ya da sorun Ã§Ã¶zÃ¼mÃ¼ sorunlu hale getirecektir.

Yasa savunmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ± durum, herhangi bir soyutlamaya Ã§ok fazla gÃ¼venmenin alta yatan iÅŸlemleri de tam anlamamayla birleÅŸince Ã§Ã¶zÃ¼lmeye Ã§alÄ±ÅŸÄ±lan problemin Ã§oÄŸunlukla daha da karmaÅŸÄ±klaÅŸmasÄ± ile sonuÃ§lanacaÄŸÄ±dÄ±r.

Ek Kaynaklar:

- [Hyrum YasasÄ±](#hyrum-yasasÄ±-arabirimlerin-Ã¶rtÃ¼lÃ¼-hukuku)

YaÅŸanmÄ±ÅŸ bir Ã¶rnek:

- [Photoshop'taki yavaÅŸ aÃ§Ä±lma problemi](https://forums.adobe.com/thread/376152). Photoshop bir zamanlar Ã§ok yavaÅŸ aÃ§Ä±lÄ±rdÄ±, hatta bazen aÃ§Ä±lmasÄ± dakikalar sÃ¼rerdi. Sorunun sebebi program her baÅŸlangÄ±Ã§ta Ã¶n tanÄ±mlÄ± yazÄ±cÄ± ile ilgili belli bilgileri Ã§ekmeye Ã§alÄ±ÅŸmasÄ± olarak gÃ¶zÃ¼kÃ¼yordu. EÄŸer yazÄ±cÄ± bir aÄŸ yazÄ±cÄ±sÄ±ysa aÃ§Ä±lma daha da uzun sÃ¼rÃ¼yordu. AÄŸ yazÄ±cÄ±larÄ±nÄ±n yerel yazÄ±cÄ±larÄ± gibi soyutlanmasÄ± kullanÄ±cÄ±lara bu kÃ¶tÃ¼ deneyimi yaÅŸatmÄ±ÅŸ oldu.

### Ã–nemsizlik YasasÄ±

[Wikipedia'da Ã–nemsizlik YasasÄ±](https://en.wikipedia.org/wiki/Law_of_triviality)

Bu yasa diyor ki, ekipler Ã¶nemsiz ve kozmetik sorunlara ciddi ve Ã¶nemli sorunlara gÃ¶re daha fazla zaman harcarlar.

En Ã§ok kullanÄ±lan kurgu Ã¶rnek nÃ¼kleer enerji reaktÃ¶rÃ¼nÃ¼ onaylayacak olan komitenin reaktÃ¶rÃ¼n genel tasarÄ±mÄ±nÄ± onaylama zamanÄ±ndan Ã§ok bisiklet parkÄ±nÄ±n tasarÄ±mÄ±nÄ± onaylamak iÃ§in zaman harcamasÄ±dÄ±r. Ã‡ok bÃ¼yÃ¼k ve karmaÅŸÄ±k konularla ilgili o alanda bir eÄŸitime, tecrÃ¼beye ve hazÄ±rlÄ±ÄŸa sahip olmadan kayda deÄŸer yorum getirmek zordur. Ä°nsanlar genelde deÄŸerli katkÄ±lar verdiklerinin gÃ¶rÃ¼lmesini isterler. DolayÄ±sÄ±yla insanlar kolayca katkÄ± verebilecekleri gerekli ve Ã¶nemli olmasa bile kÃ¼Ã§Ã¼k detaylara odaklanma eÄŸilimi gÃ¶sterirler. 

Bu kurgu Ã¶rnek 'Bike Shedding' diye bir deyimin yaygÄ±nlaÅŸmasÄ±na sebep olmuÅŸtur. TÃ¼rkÃ§e'deki 'pire iÃ§in yorgan yakmak' ya da 'attÄ±ÄŸÄ±n taÅŸ Ã¼rkÃ¼ttÃ¼ÄŸÃ¼n kurbayaÄŸa deÄŸsin' gibi deyimlere benzer.

### Unix Felsefesi

[Wikipedia'da Unix Felsefesi](https://en.wikipedia.org/wiki/Unix_philosophy)

Unix felsefesi ÅŸÃ¶yle Ã¶zetlenebilir; Bir yazÄ±lÄ±m parÃ§asÄ± olabildiÄŸince kÃ¼Ã§Ã¼k olmalÄ± ve sadece bir iÅŸi yapmaya odaklanmalÄ±dÄ±r. Bu felsefeye uymak sistemleri bÃ¼yÃ¼k, karmaÅŸÄ±k ve Ã§ok amaÃ§lÄ± programlarla oluÅŸturmak yerine kÃ¼Ã§Ã¼k, basit ve iyi tanÄ±mlanmÄ±ÅŸ parÃ§alardan daha kolayca oluÅŸturmayÄ± saÄŸlar.

'Mikro-service Mimarisi' gibi modern yaklaÅŸÄ±mlarda bu felesefenin uygulamasÄ± olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. Ã‡Ã¼nkÃ¼ bu mimari servislerin kÃ¼Ã§Ã¼k, amaÃ§ odaklÄ± ve tek bir iÅŸ yapacak ÅŸekilde geliÅŸtirilmesini ve karmaÅŸÄ±k yapÄ±larÄ±n kÃ¼Ã§Ã¼k basit bloklar halinde geliÅŸtirilmesini hedefliyor.

### The Spotify Model

[The Spotify Model on Spotify Labs](https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/)

The Spotify Model is an approach to team and organisation structure which has been popularised by 'Spotify'. In this model, teams are organised around features, rather than technologies.

The Spotify Model also popularises the concepts of Tribes, Guilds, Chapters, which are other components of their organisation structure.

### Wadler's Law

[Wadler's Law on wiki.haskell.org](https://wiki.haskell.org/Wadler's_Law)

> In any language design, the total time spent discussing a feature in this list is proportional to two raised to the power of its position.
> 
> 0. Semantics
> 1. Syntax
> 2. Lexical syntax
> 3. Lexical syntax of comments
> 
> (In short, for every hour spent on semantics, 8 hours will be spent on the syntax of comments).

Similar to [The Law of Triviality](#the-law-of-triviality), Wadler's Law states what when designing a language, the amount of time spent on language structures is disproportionately high in comparison to the importance of those features.

See also:

- [The Law of Triviality](#the-law-of-triviality)

## Principles

Principles are generally more likely to be guidelines relating to design.

### The Pareto Principle (The 80/20 Rule)

[The Pareto Principle on Wikipedia](https://en.wikipedia.org/wiki/Pareto_principle)

> Most things in life are not distributed evenly.

The Pareto Principle suggests that in some cases, the majority of results come from a minority of inputs:

- 80% of a certain piece of software can be written in 20% of the total allocated time (conversely, the hardest 20% of the code takes 80% of the time)
- 20% of the effort produces 80% of the result
- 20% of the work creates 80% of the revenue
- 20% of the bugs cause 80% of the crashes
- 20% of the features cause 80% of the usage

In the 1940s American-Romanian engineer Dr. Joseph Juran, who is widely credited with being the father of quality control, [began to apply the Pareto principle to quality issues](https://en.wikipedia.org/wiki/Joseph_M._Juran).

This principle is also known as: The 80/20 Rule, The Law of the Vital Few and The Principle of Factor Sparsity.

Real-world examples:

- In 2002 Microsoft reported that by fixing the top 20% of the most-reported bugs, 80% of the related errors and crashes in windows and office would become eliminated ([Reference](https://www.crn.com/news/security/18821726/microsofts-ceo-80-20-rule-applies-to-bugs-not-just-features.htm)).

### The Robustness Principle (Postel's Law)

[The Robustness Principle on Wikipedia](https://en.wikipedia.org/wiki/Robustness_principle)

> Be conservative in what you do, be liberal in what you accept from others.

Often applied in server application development, this principle states that what you send to others should be as minimal and conformant as possible, but you should be aim to allow non-conformant input if it can be processed.

The goal of this principle is to build systems which are robust, as they can handle poorly formed input if the intent can still be understood. However, there are potentially security implications of accepting malformed input, particularly if the processing of such input is not well tested.

### SOLID

This is an acronym, which refers to:

* S: [The Single Responsibility Principle](#the-single-responsibility-principle)
* O: [The Open/Closed Principle](#the-openclosed-principle)
* L: [The Liskov Substitution Principle](#the-liskov-substitution-principle)
* I: [The Interface Segregation Principle](#the-interface-segregation-principle)
* D: [The Dependency Inversion Principle](#the-dependency-inversion-principle)

These are key principles in [Object-Oriented Programming](#todo). Design principles such as these should be able to aid developers build more maintainable systems.

### The Single Responsibility Principle

[The Single Responsibility Principle on Wikipedia](https://en.wikipedia.org/wiki/Single_responsibility_principle)

> Every module or class should have a single responsibility only.

The first of the '[SOLID](#solid)' principles. This principle suggests that modules or classes should do one thing and one thing only. In more practical terms, this means that a single, small change to a feature of a program should require a change in one component only. For example, changing how a password is validated for complexity should require a change in only one part of the program.

Theoretically, this should make the code more robust, and easier to change. Knowing that a component which is being changed has a single responsibility only means that _testing_ that change should be easier. Using the earlier example, changing the password complexity component should only be able to affect the features which relate to password complexity. It can be much more difficult to reason about the impact of a change to a component which has many responsibilities.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Open/Closed Principle

[The Open/Closed Principle on Wikipedia](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle)

> Entities should be open for extension and closed for modification.

The second of the '[SOLID](#solid)' principles. This principle states that entities (which could be classes, modules, functions and so on) should be able to have their behaviour _extended_, but that their _existing_ behaviour should not be able to be modified.

As a hypothetical example, imagine a module which is able to turn a Markdown document into HTML. If the module could be extended to handle a newly proposed markdown feature, without modifying the module internals, then it would be open for extension. If the module could _not_ be modified by a consumer so that how existing Markdown features are handled, then it would be _closed_ for modification.

This principle has particular relevance for object-oriented programming, where we may design objects to be easily extended, but would avoid designing objects which can have their existing behaviour changed in unexpected ways.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Liskov Substitution Principle

[The Liskov Substitution Principle on Wikipedia](https://en.wikipedia.org/wiki/Liskov_substitution_principle)

> It should be possible to replace a type with a subtype, without breaking the system.

The third of the '[SOLID](#solid)' principles. This principle states that if a component relies on a type, then it should be able to use subtypes of that type, without the system failing or having to know the details of what that subtype is.

As an example, imagine we have a method which reads an XML document from a structure which represents a file. If the method uses a base type 'file', then anything which derives from 'file' should be able to be used in the function. If 'file' supports seeking in reverse, and the XML parser uses that function, but the derived type 'network file' fails when reverse seeking is attempted, then the 'network file' would be violating the principle.

This principle has particular relevance for object-oriented programming, where type hierarchies must be modeled carefully to avoid confusing users of a system.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Interface Segregation Principle

[The Interface Segregation Principle on Wikipedia](https://en.wikipedia.org/wiki/Interface_segregation_principle)

> No client should be forced to depend on methods it does not use.

The fourth of the '[SOLID](#solid)' principles. This principle states that consumers of a component should not depend on functions of that component which it doesn't actually use.

As an example, imagine we have a method which reads an XML document from a structure which represents a file. It only needs to read bytes, move forwards or move backwards in the file. If this method needs to be updated because an unrelated feature of the file structure changes (such as an update to the permissions model used to represent file security), then the principle has been invalidated. It would be better for the file to implement a 'seekable-stream' interface, and for the XML reader to use that.

This principle has particular relevance for object-oriented programming, where interfaces, hierarchies and abstract types are used to [minimise the coupling](#todo) between different components. [Duck typing](#todo) is a methodology which enforces this principle by eliminating explicit interfaces.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)
- [Duck Typing](#todo)
- [Decoupling](#todo)

### The Dependency Inversion Principle

[The Dependency Inversion Principle](https://en.wikipedia.org/wiki/Dependency_inversion_principle)

> High-level modules should not be dependent on low-level implementations.

The fifth of the '[SOLID](#solid)' principles. This principle states that higher level orchestrating components should not have to know the details of their dependencies.

As an example, imagine we have a program which read metadata from a website. We would assume that the main component would have to know about a component to download the webpage content, then a component which can read the metadata. If we were to take dependency inversion into account, the main component would depend only on an abstract component which can fetch byte data, and then an abstract component which would be able to read metadata from a byte stream. The main component would not know about TCP/IP, HTTP, HTML, etc.

This principle is complex, as it can seem to 'invert' the expected dependencies of a system (hence the name). In practice, it also means that a separate orchestrating component must ensure the correct implementations of abstract types are used (e.g. in the previous example, _something_ must still provide the metadata reader component a HTTP file downloader and HTML meta tag reader). This then touches on patterns such as [Inversion of Control](#todo) and [Dependency Injection](#todo).

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)
- [Inversion of Control](#todo)
- [Dependency Injection](#todo)

### The DRY Principle

[The DRY Principle on Wikipedia](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)

> Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.

DRY is an acronym for _Don't Repeat Yourself_. This principle aims to help developers reducing the repetition of code and keep the information in a single place and was cited in 1999 by Andrew Hunt and Dave Thomas in the book [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

> The opposite of DRY would be _WET_ (Write Everything Twice or We Enjoy Typing).

In practice, if you have the same piece of information in two (or more) different places, you can use DRY to merge them into a single one and reuse it wherever you want/need.

See also:

- [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

## Reading List

If you have found these concepts interesting, you may enjoy the following books.

- [The Mythical Man Month - Frederick P. Brooks Jr.](https://www.goodreads.com/book/show/13629.The_Mythical_Man_Month) - A classic volume on software engineering. [Brooks's Law](#brookss-law) is a central theme of the book.
- [GÃ¶del, Escher, Bach: An Eternal Golden Braid - Douglas R. Hofstadter.](https://www.goodreads.com/book/show/24113.G_del_Escher_Bach) - This book is difficult to classify. [Hofstadter's Law](#hofstadters-law) is from the book.

## TODO

Hi! If you land here, you've clicked on a link to a topic I've not written up yet, sorry about this - this is work in progress!

Feel free to [Raise an Issue](https://github.com/dwmkerr/hacker-laws/issues) requesting more details, or [Open a Pull Request](https://github.com/dwmkerr/hacker-laws/pulls) to submit your proposed definition of the topic. 
